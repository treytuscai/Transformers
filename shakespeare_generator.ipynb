{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993849c2",
   "metadata": {},
   "source": [
    "Trey Tuscai and Gordon Doore\n",
    "\n",
    "Spring 2025\n",
    "\n",
    "CS 444: Deep Learning\n",
    "\n",
    "#### Project 4: Transformers\n",
    "\n",
    "In this final notebook, we will train larger GPTs on a large corpus of prose â€” the entire works of Shakespeare. Once trained, you will be able to prompt your GPTs with some text and it will generate text that appears to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fe93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c72772",
   "metadata": {},
   "source": [
    "![Some fun](images/transformer4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b141eed",
   "metadata": {},
   "source": [
    "## Task 8. Preprocess a large corpus of text\n",
    "\n",
    "**NOTE:** This is no Task 7. It got removed due to time constraints.\n",
    "\n",
    "<!-- Let's write code to load in the works of Shakespeare (`shakespeare.txt`) and preprocess it so that we can try a transformer on the text. -->\n",
    "\n",
    "Run the test code in this section to make sure the works of Shakespeare (`shakespeare.txt`) are loaded and preprocessed properly for the transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c63dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_corpus import load_document, make_char2ind_map, make_seqs_and_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca3a1c",
   "metadata": {},
   "source": [
    "### 8a. Generate corpus and vocabulary\n",
    "\n",
    "<!-- In `preprocess_corpus.py`, implement the `load_document` function to load in the Shakespeare corpus and make the vocabulary. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eeaa288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary has 65 tokens and it should have 65.\n",
      "The vocabulary is (split up over multiple lines):\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
      "['M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n",
      "['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "and it should be:\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
      "['M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n",
      "['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "The corpus has 1115394 chars and it should have 1115394.\n",
      "-------------------------------------------------------\n",
      "The first 50 chars of the corpus is:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "and it should be:\n",
      "First Citizen:\n",
      "Before we proceed any further, hear\n",
      "-------------------------------------------------------\n",
      "The last 50 chars of the corpus is:\n",
      "eep--die, rather; wink'st\n",
      "Whiles thou art waking.\n",
      "\n",
      "and it should be:\n",
      "eep--die, rather; wink'st\n",
      "Whiles thou art waking.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus, vocab = load_document()\n",
    "\n",
    "print(f'The vocabulary has {len(vocab)} tokens and it should have 65.')\n",
    "print(f'The vocabulary is (split up over multiple lines):\\n{vocab[:25]}\\n{vocab[25:50]}\\n{vocab[50:]}\\n')\n",
    "print('and it should be:')\n",
    "print(\"\"\"['\\\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L']\n",
    "['M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n",
    "['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\"\"\")\n",
    "\n",
    "print(f'The corpus has {len(corpus)} chars and it should have 1115394.')\n",
    "print(55*'-')\n",
    "print('The first 50 chars of the corpus is:')\n",
    "print(corpus[:50])\n",
    "print('and it should be:')\n",
    "print('''First Citizen:\n",
    "Before we proceed any further, hear''')\n",
    "print(55*'-')\n",
    "print('The last 50 chars of the corpus is:')\n",
    "print(corpus[-50:])\n",
    "print('and it should be:')\n",
    "print('''eep--die, rather; wink'st\n",
    "Whiles thou art waking.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80fb62c",
   "metadata": {},
   "source": [
    "### 8b. Create char2ind map\n",
    "\n",
    "<!-- In `preprocess_corpus.py`, implement the `make_char2ind_map` function and test it below. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b736a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of your char2ind map is 65 and it should be 65.\n",
      "Keys of your char2ind map:\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "They should be \n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "Values of your char2ind map:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n",
      "They should be\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "char2ind_map = make_char2ind_map(vocab)\n",
    "\n",
    "print(f'Size of your char2ind map is {len(char2ind_map)} and it should be 65.')\n",
    "print('Keys of your char2ind map:')\n",
    "print(''.join(char2ind_map.keys()))\n",
    "print(\"They should be \\n\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")\n",
    "print('Values of your char2ind map:')\n",
    "print(list(char2ind_map.values()))\n",
    "print(\"They should be\")\n",
    "print('[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80262ef7",
   "metadata": {},
   "source": [
    "### 8c. Create sequences of int-coded texts and labels\n",
    "\n",
    "<!-- In `preprocess_corpus.py`, implement the `make_seqs_and_labels` function, which should extract sequential `seq_len` long chunks (*our desired sequence length for the transformer*) to form the sequences on which we will train the transformer. The labels/targets are just the chars shifted by 1 (i.e. the next char in the corpus). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06b8247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of your Shakespeare sequences is (4461, 250) and it should be (4461, 250).\n",
      "The shape of your Shakespeare labels is (4461, 250) and it should be (4461, 250).\n",
      "The first 15 int-coded tokens of the 1st few sequences are:\n",
      "[[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n",
      " [ 0 13 50 50 10  0 35 43  1 49 52 53 61  5 58]\n",
      " [ 1 41 47 58 47 64 43 52 57  6  1 58 46 43  1]\n",
      " [ 1 58 46 43  1 53 40 48 43 41 58  1 53 44  1]\n",
      " [31 43 41 53 52 42  1 15 47 58 47 64 43 52 10]]\n",
      "they should be:\n",
      "[[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n",
      " [ 0 13 50 50 10  0 35 43  1 49 52 53 61  5 58]\n",
      " [ 1 41 47 58 47 64 43 52 57  6  1 58 46 43  1]\n",
      " [ 1 58 46 43  1 53 40 48 43 41 58  1 53 44  1]\n",
      " [31 43 41 53 52 42  1 15 47 58 47 64 43 52 10]]\n",
      "The first 15 int-coded tokens of the last few sequences are:\n",
      "[[57 53  1 61 43 39 49 50 63  8  1 35 47 50 50]\n",
      " [ 6  0 16 53  1 52 53 58  1 53 51 47 58  1 58]\n",
      " [58 56 39 52 45 43  1 42 56 53 61 57 47 52 43]\n",
      " [42 56 53 54 54  5 42  6  1 39 57  1 40 63  1]\n",
      " [13 26 10  0 35 46 39 58  6  1 39 56 58  1 58]]\n",
      "they should be:\n",
      "[[57 53  1 61 43 39 49 50 63  8  1 35 47 50 50]\n",
      " [ 6  0 16 53  1 52 53 58  1 53 51 47 58  1 58]\n",
      " [58 56 39 52 45 43  1 42 56 53 61 57 47 52 43]\n",
      " [42 56 53 54 54  5 42  6  1 39 57  1 40 63  1]\n",
      " [13 26 10  0 35 46 39 58  6  1 39 56 58  1 58]]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 250\n",
    "seqs, labels = make_seqs_and_labels(corpus, char2ind_map, seq_len=seq_len)\n",
    "\n",
    "print(f'The shape of your Shakespeare sequences is {seqs.shape} and it should be (4461, 250).')\n",
    "print(f'The shape of your Shakespeare labels is {labels.shape} and it should be (4461, 250).')\n",
    "print('The first 15 int-coded tokens of the 1st few sequences are:')\n",
    "print(seqs[:5, :15].numpy())\n",
    "print('they should be:')\n",
    "print('''[[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0]\n",
    " [ 0 13 50 50 10  0 35 43  1 49 52 53 61  5 58]\n",
    " [ 1 41 47 58 47 64 43 52 57  6  1 58 46 43  1]\n",
    " [ 1 58 46 43  1 53 40 48 43 41 58  1 53 44  1]\n",
    " [31 43 41 53 52 42  1 15 47 58 47 64 43 52 10]]''')\n",
    "\n",
    "print('The first 15 int-coded tokens of the last few sequences are:')\n",
    "print(seqs[-5:, :15].numpy())\n",
    "print('they should be:')\n",
    "print('''[[57 53  1 61 43 39 49 50 63  8  1 35 47 50 50]\n",
    " [ 6  0 16 53  1 52 53 58  1 53 51 47 58  1 58]\n",
    " [58 56 39 52 45 43  1 42 56 53 61 57 47 52 43]\n",
    " [42 56 53 54 54  5 42  6  1 39 57  1 40 63  1]\n",
    " [13 26 10  0 35 46 39 58  6  1 39 56 58  1 58]]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc6bc9",
   "metadata": {},
   "source": [
    "### 8d. Add padding char to dictionary\n",
    "\n",
    "**TODO:** Add the usual padding char (`'#'`) to the char2ind map to the next available int slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d832fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of your char2ind map is 66 and it should be 66.\n",
      "Keys of your char2ind map:\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#\n",
      "They should be \n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#\n",
      "Values of your char2ind map:\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n",
      "They should be\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]\n"
     ]
    }
   ],
   "source": [
    "# Add padding char to dictionary\n",
    "padding_char = '#'\n",
    "next_available_index = len(char2ind_map)\n",
    "char2ind_map[padding_char] = next_available_index\n",
    "print(f'Size of your char2ind map is {len(char2ind_map)} and it should be 66.')\n",
    "print('Keys of your char2ind map:')\n",
    "print(''.join(char2ind_map.keys()))\n",
    "print(\"They should be \\n\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz#\")\n",
    "print('Values of your char2ind map:')\n",
    "print(list(char2ind_map.values()))\n",
    "print(\"They should be\")\n",
    "print('[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df99ac1",
   "metadata": {},
   "source": [
    "## Task 9. Train GPT on Shakespeare\n",
    "\n",
    "Now we are ready to train a GPT on the works of Shakespeare!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25755e",
   "metadata": {},
   "source": [
    "### 9a. Build `GPTMini6`\n",
    "\n",
    "We will use a deeper transformer called `GPTMini6` for training on the Shakespeare corpus. Build the neural network then check the summary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d91153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpts import GPTMini6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c69735c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(output) shape: [1, 15, 9]\n",
      "TransformerBlock_5:\n",
      "\tTransformerBlock_5/MLP:\n",
      "\tDropout layer output(TransformerBlock_5/MLP/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_5/MLP/dense_1) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_5/MLP/dense_0) shape: [1, 15, 1536]\n",
      "\tTransformerBlock_5/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_5/multihead_attention/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/dense_1) shape: [1, 15, 384]\n",
      "\tTransformerBlock_5/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_5/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformerBlock_5/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
      "TransformerBlock_4:\n",
      "\tTransformerBlock_4/MLP:\n",
      "\tDropout layer output(TransformerBlock_4/MLP/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_4/MLP/dense_1) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_4/MLP/dense_0) shape: [1, 15, 1536]\n",
      "\tTransformerBlock_4/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_4/multihead_attention/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/dense_1) shape: [1, 15, 384]\n",
      "\tTransformerBlock_4/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_4/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformerBlock_4/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
      "TransformerBlock_3:\n",
      "\tTransformerBlock_3/MLP:\n",
      "\tDropout layer output(TransformerBlock_3/MLP/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_3/MLP/dense_1) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_3/MLP/dense_0) shape: [1, 15, 1536]\n",
      "\tTransformerBlock_3/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_3/multihead_attention/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/dense_1) shape: [1, 15, 384]\n",
      "\tTransformerBlock_3/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_3/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformerBlock_3/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
      "TransformerBlock_2:\n",
      "\tTransformerBlock_2/MLP:\n",
      "\tDropout layer output(TransformerBlock_2/MLP/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_2/MLP/dense_1) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_2/MLP/dense_0) shape: [1, 15, 1536]\n",
      "\tTransformerBlock_2/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_2/multihead_attention/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/dense_1) shape: [1, 15, 384]\n",
      "\tTransformerBlock_2/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_2/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformerBlock_2/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
      "TransformerBlock_1:\n",
      "\tTransformerBlock_1/MLP:\n",
      "\tDropout layer output(TransformerBlock_1/MLP/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_1/MLP/dense_1) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_1/MLP/dense_0) shape: [1, 15, 1536]\n",
      "\tTransformerBlock_1/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_1/multihead_attention/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/dense_1) shape: [1, 15, 384]\n",
      "\tTransformerBlock_1/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_1/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformerBlock_1/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
      "TransformerBlock_0:\n",
      "\tTransformerBlock_0/MLP:\n",
      "\tDropout layer output(TransformerBlock_0/MLP/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_0/MLP/dense_1) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_0/MLP/dense_0) shape: [1, 15, 1536]\n",
      "\tTransformerBlock_0/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_0/multihead_attention/dropout) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/dense_1) shape: [1, 15, 384]\n",
      "\tTransformerBlock_0/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_0/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
      "\tTransformerBlock_0/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
      "PositionalEncodingBlock:\n",
      "\tDropout layer output(PositionalEncodingBlock/dropout) shape: [1, 15, 384]\n",
      "\tPositional encoding layer output(PositionalEncodingBlock/positional_enc_layer) shape: [1, 15, 384]\n",
      "Embedding layer output(EmbeddingLayer) shape: [1, 15, 384]\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TODO: Set padding_char_enc to the int coded padding token below\n",
    "padding_char_enc = char2ind_map['#']\n",
    "myminigpt = GPTMini6(vocab_sz=9, seq_len=15, padding_char_enc=padding_char_enc)\n",
    "myminigpt.compile(loss='temporal_cross_entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ddd95",
   "metadata": {},
   "source": [
    "The above cell should output:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(output) shape: [1, 15, 9]\n",
    "TransformerBlock_5:\n",
    "\tTransformerBlock_5/MLP:\n",
    "\tDropout layer output(TransformerBlock_5/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_5/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_5/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_5/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_5/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_5/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_4:\n",
    "\tTransformerBlock_4/MLP:\n",
    "\tDropout layer output(TransformerBlock_4/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_4/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_4/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_4/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_4/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_4/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_3:\n",
    "\tTransformerBlock_3/MLP:\n",
    "\tDropout layer output(TransformerBlock_3/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_3/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_3/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_3/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_3/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_3/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_2:\n",
    "\tTransformerBlock_2/MLP:\n",
    "\tDropout layer output(TransformerBlock_2/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_2/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_2/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_2/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_2/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_2/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_1:\n",
    "\tTransformerBlock_1/MLP:\n",
    "\tDropout layer output(TransformerBlock_1/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_1/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_1/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_1/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_1/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_1/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "TransformerBlock_0:\n",
    "\tTransformerBlock_0/MLP:\n",
    "\tDropout layer output(TransformerBlock_0/MLP/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/MLP/dense_1) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/MLP/dense_0) shape: [1, 15, 1536]\n",
    "\tTransformerBlock_0/multihead_attention:\n",
    "\tDropout layer output(TransformerBlock_0/multihead_attention/dropout) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/dense_1) shape: [1, 15, 384]\n",
    "\tTransformerBlock_0/multihead_attention/attention:\n",
    "\tDropout layer output(TransformerBlock_0/multihead_attention/attention/dropout) shape: [1, 6, 15, 15]\n",
    "\tTransformerBlock_0/multihead_attention/qkv_block:\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_v) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_k) shape: [1, 15, 384]\n",
    "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_q) shape: [1, 15, 384]\n",
    "PositionalEncodingBlock:\n",
    "\tDropout layer output(PositionalEncodingBlock/dropout) shape: [1, 15, 384]\n",
    "\tPositional encoding layer output(PositionalEncodingBlock/positional_enc_layer) shape: [1, 15, 384]\n",
    "Embedding layer output(EmbeddingLayer) shape: [1, 15, 384]\n",
    "---------------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86680bd4",
   "metadata": {},
   "source": [
    "### 9b. Train `GPTMini6` on the works of Shakespeare\n",
    "\n",
    "Use default hyperparameters except for the following:\n",
    "- For the validation set, use the 1st 200 sequences. For the training set, use all sequences beyond the 1st 200.\n",
    "- Batch size of `64`.\n",
    "- Patience of `15`.\n",
    "- Learning rate decay patience of `9`.\n",
    "- Learning rate should be allowed to decay no more than `3` times.\n",
    "- Limit training to `100` epochs maximum.\n",
    "\n",
    "Make a well-labeled plot showing the **training and validation loss** over the course of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658f5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output(output) shape: [1, 250, 66]\n",
      "TransformerBlock_5:\n",
      "\tTransformerBlock_5/MLP:\n",
      "\tDropout layer output(TransformerBlock_5/MLP/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_5/MLP/dense_1) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_5/MLP/dense_0) shape: [1, 250, 1536]\n",
      "\tTransformerBlock_5/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_5/multihead_attention/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/dense_1) shape: [1, 250, 384]\n",
      "\tTransformerBlock_5/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_5/multihead_attention/attention/dropout) shape: [1, 6, 250, 250]\n",
      "\tTransformerBlock_5/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_v) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_k) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_5/multihead_attention/qkv_block/dense_q) shape: [1, 250, 384]\n",
      "TransformerBlock_4:\n",
      "\tTransformerBlock_4/MLP:\n",
      "\tDropout layer output(TransformerBlock_4/MLP/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_4/MLP/dense_1) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_4/MLP/dense_0) shape: [1, 250, 1536]\n",
      "\tTransformerBlock_4/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_4/multihead_attention/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/dense_1) shape: [1, 250, 384]\n",
      "\tTransformerBlock_4/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_4/multihead_attention/attention/dropout) shape: [1, 6, 250, 250]\n",
      "\tTransformerBlock_4/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_v) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_k) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_4/multihead_attention/qkv_block/dense_q) shape: [1, 250, 384]\n",
      "TransformerBlock_3:\n",
      "\tTransformerBlock_3/MLP:\n",
      "\tDropout layer output(TransformerBlock_3/MLP/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_3/MLP/dense_1) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_3/MLP/dense_0) shape: [1, 250, 1536]\n",
      "\tTransformerBlock_3/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_3/multihead_attention/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/dense_1) shape: [1, 250, 384]\n",
      "\tTransformerBlock_3/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_3/multihead_attention/attention/dropout) shape: [1, 6, 250, 250]\n",
      "\tTransformerBlock_3/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_v) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_k) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_3/multihead_attention/qkv_block/dense_q) shape: [1, 250, 384]\n",
      "TransformerBlock_2:\n",
      "\tTransformerBlock_2/MLP:\n",
      "\tDropout layer output(TransformerBlock_2/MLP/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_2/MLP/dense_1) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_2/MLP/dense_0) shape: [1, 250, 1536]\n",
      "\tTransformerBlock_2/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_2/multihead_attention/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/dense_1) shape: [1, 250, 384]\n",
      "\tTransformerBlock_2/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_2/multihead_attention/attention/dropout) shape: [1, 6, 250, 250]\n",
      "\tTransformerBlock_2/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_v) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_k) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_2/multihead_attention/qkv_block/dense_q) shape: [1, 250, 384]\n",
      "TransformerBlock_1:\n",
      "\tTransformerBlock_1/MLP:\n",
      "\tDropout layer output(TransformerBlock_1/MLP/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_1/MLP/dense_1) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_1/MLP/dense_0) shape: [1, 250, 1536]\n",
      "\tTransformerBlock_1/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_1/multihead_attention/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/dense_1) shape: [1, 250, 384]\n",
      "\tTransformerBlock_1/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_1/multihead_attention/attention/dropout) shape: [1, 6, 250, 250]\n",
      "\tTransformerBlock_1/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_v) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_k) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_1/multihead_attention/qkv_block/dense_q) shape: [1, 250, 384]\n",
      "TransformerBlock_0:\n",
      "\tTransformerBlock_0/MLP:\n",
      "\tDropout layer output(TransformerBlock_0/MLP/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_0/MLP/dense_1) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_0/MLP/dense_0) shape: [1, 250, 1536]\n",
      "\tTransformerBlock_0/multihead_attention:\n",
      "\tDropout layer output(TransformerBlock_0/multihead_attention/dropout) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/dense_1) shape: [1, 250, 384]\n",
      "\tTransformerBlock_0/multihead_attention/attention:\n",
      "\tDropout layer output(TransformerBlock_0/multihead_attention/attention/dropout) shape: [1, 6, 250, 250]\n",
      "\tTransformerBlock_0/multihead_attention/qkv_block:\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_v) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_k) shape: [1, 250, 384]\n",
      "\tDense layer output(TransformerBlock_0/multihead_attention/qkv_block/dense_q) shape: [1, 250, 384]\n",
      "PositionalEncodingBlock:\n",
      "\tDropout layer output(PositionalEncodingBlock/dropout) shape: [1, 250, 384]\n",
      "\tPositional encoding layer output(PositionalEncodingBlock/positional_enc_layer) shape: [1, 250, 384]\n",
      "Embedding layer output(EmbeddingLayer) shape: [1, 250, 384]\n",
      "---------------------------------------------------------------------------\n",
      "Tensor(\"Reshape_32:0\", shape=(64, 250), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function AtomicFunction.__del__ at 0x154781d80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/treytuscai/miniforge3/envs/cs444/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 302, in __del__\n",
      "    self._bound_context.remove_function(self.name)\n",
      "  File \"/Users/treytuscai/miniforge3/envs/cs444/lib/python3.10/site-packages/tensorflow/python/eager/context.py\", line 1530, in remove_function\n",
      "    pywrap_tfe.TFE_ContextRemoveFunction(self._handle, name)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_32:0\", shape=(64, 250), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Load the document and create the char2ind map\n",
    "corpus, vocab = load_document()\n",
    "char2ind_map = make_char2ind_map(vocab)\n",
    "\n",
    "# Define sequence and labels\n",
    "seq_len = 250\n",
    "seqs, labels = make_seqs_and_labels(corpus, char2ind_map, seq_len=seq_len)\n",
    "\n",
    "# Add padding character to the char2ind map\n",
    "padding_char = '#'\n",
    "next_available_index = len(char2ind_map)\n",
    "char2ind_map[padding_char] = next_available_index\n",
    "\n",
    "# Split data\n",
    "seqs_train, seqs_val = seqs[200:], seqs[:200]\n",
    "labels_train, labels_val = labels[200:], labels[:200]\n",
    "\n",
    "# Set vocab size and padding character encoding\n",
    "vocab_sz = len(char2ind_map)\n",
    "padding_char_enc = char2ind_map['#']\n",
    "\n",
    "# Train\n",
    "minigpt = GPTMini6(vocab_sz=vocab_sz, seq_len=seq_len, padding_char_enc=padding_char_enc)\n",
    "minigpt.compile(loss='temporal_cross_entropy')\n",
    "train_loss_hist, val_loss_hist, _, _ = minigpt.fit(seqs_train, labels_train, seqs_val, labels_val, batch_size=64, patience=15, max_epochs=100, lr_max_decays=3, lr_patience=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845cdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0bf1f9",
   "metadata": {},
   "source": [
    "### 9c. Prompt GPT to generate Shakespearian text  \n",
    "\n",
    "Have your GPT to generate a large amount of text (e.g. generate 5000 chars) that follows a prompt of your choice (a string containing few words or a sentence).\n",
    "\n",
    "**Guidelines**\n",
    "1. Use your `make_ind2char_mapping` from the math datasets to make the reverse map.\n",
    "2. Use the `'distributed'` method for generating text.\n",
    "\n",
    "When you turn in your project, include an example of at least one long passage of generated text by your GPT below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from addition_dataset import make_ind2char_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80384f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('***final output***')\n",
    "print(''.join(gen_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c7c5a",
   "metadata": {},
   "source": [
    "### 9d. Questions\n",
    "\n",
    "**Question 9:** Rerun your generation using the `'max'` method. Which method generates better sounding/more interesting text? **Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94714d5f",
   "metadata": {},
   "source": [
    "**Answer 9:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3523a5",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec837871",
   "metadata": {},
   "source": [
    "#### 1. Generate text based on other corpora\n",
    "\n",
    "Train one of your GPTs on a different text dataset and use it to generate text that resembles that body of work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ab216c",
   "metadata": {},
   "source": [
    "#### 2. GPT-1\n",
    "\n",
    "Train OpenAI's GPT-1 model. It has the same architecture as `GPTMini6` except it has:\n",
    "- 12 stacked Transformer Blocks\n",
    "- 12 attention heads\n",
    "- Embedding dimension of 768\n",
    "- Dropout rate of 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6310e422",
   "metadata": {},
   "source": [
    "#### 3. GPT-2\n",
    "\n",
    "Train a model in the family of OpenAI's GPT2 models. It has the same architecture as `GPTMini6` except it has different values for (number of transformer blocks, embedding dimension, attention heads):\n",
    "\n",
    "**GPT-2 Medium:** (24, 1024, 16)<br/>\n",
    "**GPT-2 Large:** (36, 1280, 20)<br/>\n",
    "**GPT-2 XL:** (48, 1600, 25)\n",
    "\n",
    "Feel free to adapt/pare down based on training time and GPU resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b1009",
   "metadata": {},
   "source": [
    "#### 4. More complex arithmetic\n",
    "\n",
    "Explore any of the following:\n",
    "- Train your transformers to perform addition and/or multiplication with larger numbers.\n",
    "- Add support for negative integer operands.\n",
    "- Allow for longer chains of operands (e.g. `1+1+1+1=4`)\n",
    "- Add support for subtraction and/or other arithmetic operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e529e9",
   "metadata": {},
   "source": [
    "#### 5. Explore hyperparameters\n",
    "\n",
    "Explore how any of the following affects the quality of the generated text and/or loss:\n",
    "- Sequence length\n",
    "- Embedding dimension"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs444",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
